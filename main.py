# -*- coding: utf-8 -*-
"""NLP _GRAD_ASSIGNMENT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IV4JGQYrQQVgT8RiYi0m7jfWXqU2VyFc
"""

pip install -qq pandas faiss-cpu sentence-transformers

import pandas as pd
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer

df = pd.read_csv("collaborative_book_metadata.csv")


def create_doc(row):
    return f"Title: {row['title']}\nAuthor: {row['name']}\nGenre: {row['genre']}\nDescription: {row['description']}"

documents = df.apply(create_doc, axis=1).tolist()


metadata = df[['title', 'name', 'genre', 'description']].to_dict(orient='records')


model = SentenceTransformer('all-mpnet-base-v2')
# model = SentenceTransformer('all-MiniLM-L6-v2')
embeddings = model.encode(documents, show_progress_bar=True)

dim = embeddings.shape[1]
index = faiss.IndexFlatL2(dim)
index.add(np.array(embeddings))


faiss.write_index(index, "book_metadata_faiss.index")


index = faiss.read_index("book_metadata_faiss.index")


def search_faiss(query, top_k=5):

    query_vector = model.encode([query])


    distances, indices = index.search(np.array(query_vector), top_k)


    results = []
    for idx in indices[0]:
        result = metadata[idx]
        result['score'] = float(distances[0][list(indices[0]).index(idx)])
        results.append(result)
    return results

def search_faiss_and_keywords(query, top_k=5):

    query_vector = model.encode([query])
    distances, indices = index.search(np.array(query_vector), top_k)


    semantic_results = []
    for idx in indices[0]:
        result = metadata[idx].copy()
        result['score'] = float(distances[0][list(indices[0]).index(idx)])
        result['source'] = 'semantic'
        semantic_results.append(result)


    keyword_results = []
    query_lower = query.lower()
    for i, doc in enumerate(metadata):

        text = doc.get('text', '').lower()
        if query_lower in text:
            result = doc.copy()
            result['score'] = 1.0  
            result['source'] = 'keyword'
            keyword_results.append(result)


    seen_ids = set()
    combined_results = []

    for res in semantic_results + keyword_results:
        doc_id = res.get('id', res.get('text'))  # use 'id' if available
        if doc_id not in seen_ids:
            combined_results.append(res)
            seen_ids.add(doc_id)
        if len(combined_results) >= top_k:
            break

    return combined_results


query = "searching for woman realted books"
results = search_faiss_and_keywords(query)


for i, res in enumerate(results):
    print(f"\nResult {i+1} (Score: {res['score']:.2f})")
    print(f"Title: {res['title']}")
    print(f"Author: {res['name']}")
    print(f"Genre: {res['genre']}")
    print(f"Description: {res['description'][:200]}...")

